NatafIntMethod ='GH', NoEval=9, polydeg=8)
Sim=SimARTAp(ARTApar = ARTApar, steps = 24*365*10^2, stand = 0)
acf(Sim$X)
lines(0:(length(ACF)-1), ACF)
acf(Sim$X)
lines(0:(length(ACF)-1), ACF)
acf(Sim$X)
lines(0:(length(ACF)-1), ACF)
ACF=acsCAS(param=c(1, 0.6), lag=24*50, var=3)
fx='qzi'
ACF=acsCAS(param=c(1, 0.6), lag=24*50, var=1)
pfx=list(Distr=qgamma, p0=0.9, shape=0.1, scale=3)
ARTApar=EstARTAp(ACF=ACF, maxlag=0, dist=fx, params=pfx,
NatafIntMethod ='GH', NoEval=9, polydeg=8)
Sim=SimARTAp(ARTApar = ARTApar, steps = 24*365*10^2, stand = 1)
acf(Sim$X)
lines(0:(length(ACF)-1), ACF)
Xmat=matrix(data = Sim$X, ncol = 24, byrow = T)
Xsum=rowSums(Xmat)/24
p0sum=SMATAPKG::pdry(Xsum)
p0sim=SMATAPKG::pdry(Sim$X)
p0sum/p0sim
NZID=which(Xsum!=0)
temp=Xmat[NZID,]
plot(NA,NA, xlim=c(0, 24), ylim=c(0,1))
CC=matrix(NA, ncol=24, nrow = length(NZID))
PD=rep(NA, length(NZID))
for (i in 1:length(NZID)) {
cc=acf(temp[i,], plot = F, lag.max = 23)$acf
# lines(0:23, cc)
CC[i,]=cc
PD[i]=SMATAPKG::pdry(temp[i,])
}
colMeans(CC)
plot(Xsum[NZID], PD)
cor(Xsum[NZID], PD)
plot(Xsum[NZID], 1-PD)
cor(Xsum[NZID], 1-PD)
hist(PD)
mean(PD)
SMATAPKG::pdry(temp)
p0sum/p0sim
p0sum
p0sim
(1-p0sim)/(1-p0sum)
1-(1-p0sim)/(1-p0sum)
(1-p0sim)/(1-p0sum)
SMATAPKG::pdry(temp)
1-(1-p0sim)/(1-p0sum)
(p0sim)/(p0sum)
1-(p0sim)/(p0sum)
SMATAPKG::pdry(temp)
1-(1-p0sim)/(1-p0sum)
1-SMATAPKG::pdry(temp)
(1-p0sim)/(1-p0sum)
mean(temp)
mean(Xsum)
mean(Xsum)/(24*(1-p0sum))
mean(temp)
mean(Xsum)/(24*(1-p0sum))
24*mean(Xsum)/(24*(1-p0sum))
mean(temp)
(24*mean(Xsum))/(24*(1-p0sum))
plot(Xsum[NZID], 1-PD)
1-SMATAPKG::pdry(temp)
(1-p0sim)/(1-p0sum)
mean(temp)
(24*mean(Xsum))/(24*(1-p0sum))
mean(Sim$X)
plot(Xsum[NZID], 1-PD, log='x')
plot(Xsum[NZID], 1-PD, log='xy')
plot(Xsum[NZID], 1-PD, log='y')
plot(Xsum[NZID], 1-PD, log='')
1-SMATAPKG::pdry(temp)
(1-p0sim)/(1-p0sum)
mean(temp)
(24*mean(Xsum))/(24*(1-p0sum))
p0sim
1-SMATAPKG::pdry(temp)
acf(as.vector(t(Xmat[NZID,])))
lines(0:(length(ACF)-1), ACF)
mean(temp)
mean(temp)*(1-p0sim)/(1-p0sum)
(1-p0sim)/(1-p0sum)
mean(Sim$X[Sim$X>0])
mean(temp)*(1-p0sim)/(1-p0sum)
mean(temp)/(1-p0sim)/(1-p0sum)
mean(Sim$X[Sim$X>0])
mean(temp)
mean(temp[temp>0])
mean(temp)
(24*mean(Xsum))/(24*(1-p0sum))
mean(Sim$X[Sim$X>0])
mean(temp[temp>0])
var(Sim$X[Sim$X>0])
var(temp[temp>0])
mean(PD)
1-mean(PD)
1-SMATAPKG::pdry(temp)
(1-p0sim)/(1-p0sum)
1-mean(PD)
mean(temp)
(24*mean(Xsum))/(24*(1-p0sum))
mean(Sim$X[Sim$X>0])
mean(temp[temp>0])
var(Sim$X[Sim$X>0])
var(temp[temp>0])
moments::skewness(Sim$X[Sim$X>0])
moments::skewness(Sim$X[Sim$X>0])
moments::skewness(temp[temp>0])
1-mean(PD)
mean(PD)
plot(Xsum[NZID], 1-PD, log='')
colMeans(CC)
hist(PD)
hist(1-PD)
plot(Xsum[NZID], 1-PD, log='')
1-mean(PD)
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'mle')
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'mle', start = list(shape1=1, shape2=1))
(1-PD)
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'qme', probs=c(0.2, 0.5), start = list(shape1=1, shape2=1))
plot(fitB)
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'gme', probs=c(0.2, 0.5), start = list(shape1=1, shape2=1))
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'mme', probs=c(0.2, 0.5), start = list(shape1=1, shape2=1))
plot(fitB)
var(1-PD)
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'mme', probs=c(0.2, 0.5), start = list(shape1=1, shape2=1))
plot(fitB) # actuar has an mbeta function
fitB=fitdistrplus::fitdist(data = (1-PD), distr = 'beta', method = 'qme', probs=c(0.2, 0.5), start = list(shape1=1, shape2=1))
plot(fitB) # actuar has an mbeta function
which.max(Xsum)
MAXID=which.max(Xsum)
plot(Xmat[MAXID,])
barplot(Xmat[MAXID,])
text(c(1,1), 'ada')
barplot(Xmat[MAXID,])
text(c(1,10), 'ada')
text(1, 10, 'ada')
barplot(Xmat[MAXID,])
text(1, 10, 'ada')
text(1, 10, paste0('Rain sum: ', Xsum[MAXID]))
Xsum[MAXID]
barplot(Xmat[MAXID,])
text(1, 10, paste0('Rain sum: ', round(Xsum[MAXID],2)))
text(1, 10, paste0('Rain sum: ', round(Xsum[MAXID],2)), col='red')
barplot(Xmat[MAXID,])
text(5, 10, paste0('Rain sum: ', round(Xsum[MAXID],2)), col='red')
barplot(Xmat[MAXID,])
text(5, 10, paste0('Rain sum: ', 24*round(Xsum[MAXID],2)), col='red')
sum(Xmat[MAXID,])
library(evir)
data(bmw)
bmw
out <- gev(bmw, "month", )
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out, 40)
out <- gev(bmw, "month", )
out
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40)
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40, add = T)
# Fit GEV to monthly maxima of daily returns on BMW share price
plot(rlevel.gev(out = out, k.blocks = 40, add = T))
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40, add = T)
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40, add = F)
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40)
out
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40)[2]
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 200)[2]
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40, add = TRUE)
out <- gev(bmw, "annual", )
out <- gev(bmw, "year", )
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 40, add = TRUE)
out <- gev(bmw, "month", )
12*3
40*!2
40*12
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 480, add = TRUE)
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 100*12, add = TRUE)
out <- gev(bmw, "year", )
# Fit GEV to monthly maxima of daily returns on BMW share price
rlevel.gev(out = out, k.blocks = 100, add = TRUE)
acf(as.vector(bmw))
plot(bmw)
plot(bmw, t='l')
head(bmw)
data(bmw)
bmw
plot(bmw, t='l')
bmw
plot(bmw)
bmw
as.xts(bmw)
head(bmw)
class(bmw)
library(xts)
library(lubridate)
library(rdwd)
library(readr)
library(ggplot2)
library(scales) # YT: this one is also needed.
cwd <- getwd()
source(file.path(cwd,"Functions","delim2xts.R"))
file <- "WTPInletData.txt"
file_path <- file.path(cwd,file)
date_format <- "%d/%m/%Y %H:%M"
time_zone <- "UTC"
data <- delim2xts(file_path = file_path, date_format = date_format, time_zone = "UTC")
source(file.path(cwd,"Functions","check_missing.R"))
missing <- check_missing(data, c("months","years"))
#View(missing$prct_missing)
missing$list_months$figure
source(file.path(cwd,"Functions","plot_missing.R"))
plt_missing <- plot_missing(data[,3])
plt_missing
source(file.path(cwd,"Functions","basic_stats.R"))
bstats <- basic_stats(data[,4], pstart = '2002',pend = '2005', xpos_table = 0.1)
View(bstats)
stats_table
bstats <- stats_table
bstats$stats_table
bstats$quantiles_table
bstats$plot
#manual_season, e.g. dry and wet season
agg_ts <- aggregate_ts(data[,4], periods = c("months","quarters","years"), FUN = 'mean', season_end = c("10-15","04-01"),
mseason_title = "Arbitrary")
source(file.path(cwd,"Functions","aggregate_ts.R"))
source(file.path(cwd,"Functions","monthly_stats.R"))
monthly_sts <- monthly_stats(data[,4],base_scale = TRUE, FUN = "mean")
monthly_sts$faggre
monthly_sts$fbase
monthly_sts$fbase
getwd()
setwd("C:/Users/Admin/Documents")
getwd()
devtools::create("anyFit")
setwd("C:/Users/Admin/Documents/KNMI_example")
devtools::create("anyFit")
here::
install.packages("here")
here::dr_here()
setwd("C:/Users/Admin/Documents")
devtools::create("anyFit")
setwd("C:/Users/Admin/Documents/anyFit")
devtools::document()
devtools::use_vignette("Introduction")
install.packages("usethat")
usethis::use_vignette("Introduction")
devtools::install()
devtools::install()
?delim2xts
devtools::document()
devtools::install()
?delim2xts
?delim2xts
devtools::document()
devtools::install()
?delim2xts
?delim2xts
devtools::install()
?delim2xts
anyFit::delim2xts()
library(anyFit)
?delim2xts
devtools::document()
devtools::install()
library(anyFit)
?delim2xts
library(anyFit)
?delim2xts
devtools::document()
library(anyFit)
?aggregate_xts
git config --global user.email "gapouliasis@gmail.com"
devtools::document()
devtools::document()
usethis::use_tidy_description()
usethis::use_tidy_dependencies()
renv::dependencies()
install.packages()
install.packages("renv")
renv::dependencies()
a=renv::dependencies()
b = unique(a$Package)
usethis::use_package(b)
b[1]
for (i in 1:39){usethis::use_package(b[i])}
b
for (i in 28:39){usethis::use_package(b[i])}
devtools::document()
?Exponential
file_path_nc <- system.file("extdata", "rr_ens_mean_0.25deg_reg_2011-2022_v27.0e.nc", package = "anyFit")
varname = "rr"
country = "Belgium"
nc_data = ncdf4::nc_open(filename = filename)
library(anyFit)
filename = file_path_nc
nc_data = ncdf4::nc_open(filename = filename)
nc_brick = raster::brick(filename, varname = varname, level = 1)
#world_data = readRDS("data/world_data.rds")
if (!is.na(country)){
countries = world_data$name
if (country %in% countries){
mask = subset(world_data, name==country)
r2 <- raster::crop(nc_brick, raster::extent(mask))
r3 <- raster::mask(r2, mask = mask)
}else{
stop("Country name is incorrect")
}
}else if(!is.na(continent)){
continents = world_data$continent
if (continent %in% continents){
mask = subset(world_data, continent==continent)
r2 <- raster::crop(nc_brick, raster::extent(mask))
r3 <- raster::mask(r2, mask = mask)
}else{
stop("Continent name is incorrect")
}
}else if(!is.na(continent)){
mask = rgdal::readOGR(shapefile)
r2 <- raster::crop(nc_brick, raster::extent(mask))
r3 <- raster::mask(r2, mask = mask)
}else{
r3 = nc_brick
}
t = raster::rasterToPoints(r3)
tt = t(t)
coords = t(tt[c(1,2),])
tt = tt[-c(1,2),]
dates = rownames(tt)
temp_dates = gsub("X",replacement = "",x=dates)
funs = c(ymd, ydm, mdy, myd, dmy, dym,
ymd_h, dmy_h, mdy_h, ydm_h,
ymd_hm, dmy_hm, mdy_hm, ydm_hm,
ymd_hms, dmy_hms, mdy_hms, ydm_hms)
for (tfun in funs){
param_list = list(data = temp_dates)
param_list$tz = 'UTC'
dates = tryCatch({do.call(tfun,param_list)},
warning = function(w) {})
if (!is.null(dates)){
break
}
}
ncdf_xts = xts(x = tt,order.by = dates)
list_out = list(raster = r3, ncdf_xts = ncdf_xts, dates = dates, coordinates = coords)
data = list_out$raster
data_raster = list_out$raster
annual_data = period_apply_nc(data_raster, period = "years", FUN = "sum")
annual_plot = nc_ggplot(annual_data,title = TRUE,viridis.option = "turbo",
legend.title = "Annual Precipitation (mm)", common.legend = TRUE, legend = "bottom")
annual_plot
shapefile = "C:/Users/gapou/Downloads/world-administrative-boundaries/world-administrative-boundaries.shp"
nc_brick = raster::brick(filename, varname = varname, level = 1)
mask = rester::shapefile(shapefile)
mask = raster::shapefile(shapefile)
r2 <- raster::crop(nc_brick, raster::extent(mask))
r3 <- raster::mask(r2, mask = mask)
t = raster::rasterToPoints(r3)
tt = t(t)
coords = t(tt[c(1,2),])
tt = tt[-c(1,2),]
dates = rownames(tt)
temp_dates = gsub("X",replacement = "",x=dates)
funs = c(ymd, ydm, mdy, myd, dmy, dym,
ymd_h, dmy_h, mdy_h, ydm_h,
ymd_hm, dmy_hm, mdy_hm, ydm_hm,
ymd_hms, dmy_hms, mdy_hms, ydm_hms)
for (tfun in funs){
param_list = list(data = temp_dates)
param_list$tz = 'UTC'
dates = tryCatch({do.call(tfun,param_list)},
warning = function(w) {})
if (!is.null(dates)){
break
}
}
ncdf_xts = xts(x = tt,order.by = dates)
list_out = list(raster = r3, ncdf_xts = ncdf_xts, dates = dates, coordinates = coords)
data_raster = list_out$raster
annual_data = period_apply_nc(data_raster, period = "years", FUN = "sum")
annual_plot = nc_ggplot(annual_data,title = TRUE,viridis.option = "turbo",
legend.title = "Annual Precipitation (mm)", common.legend = TRUE, legend = "bottom")
annual_plot
a=renv::dependencies()
b = unique(a$Package)
b
devtools::document()
View(a)
devtools::document()
devtools::install()
library(anyFit)
library(anyFit)
file_path <- system.file("extdata", "KNMI_Daily.csv", package = "anyFit")
time_zone <- "UTC"
data <- delim2xts(file_path = file_path,
time_zone = "UTC", delim = " ", strict_step = TRUE)
params <- fitlm_expweibull(data[,4], ignore_zeros = TRUE)
data[,4]
x = data[,4]
ignore_zeros = TRUE
zero_threshold = 0.01
# Important: MEANT to be fitted ONLY to NON-NEGATIVE data.
# The potential inlcusion of zeros or NAs to "x" is hanlded by the 2 lines below.
xNZ <- na.omit(coredata(x))
if (ignore_zeros == TRUE){
xNZ <- x[x > zero_threshold,]
xNZ <- na.omit(coredata(xNZ))
}
library(xts)
# Important: MEANT to be fitted ONLY to NON-NEGATIVE data.
# The potential inlcusion of zeros or NAs to "x" is hanlded by the 2 lines below.
xNZ <- na.omit(coredata(x))
if (ignore_zeros == TRUE){
xNZ <- x[x > zero_threshold,]
xNZ <- na.omit(coredata(xNZ))
}
lm=lmom::samlmu(xNZ)
# Implement Step1
parwei=lmom::pelwei(lmom = lm, bound = 0)[2:3]
# Implement Step2
START=c(parwei[1], parwei[2], 1)
fit=lmom::pelq(lmom = lm[1:3], qfunc = qexpweibull, start = START, type = 's')$para
fit=list(scale=as.vector(fit[1]), shape1=as.vector(fit[2]), shape2=as.vector(fit[3]))
GoF <- GOF_tests(x = x, fit = fit, distribution = 'expweibull')
GOF_tests = function(x, fit, distribution){
u_emp <- rank(x, na.last = NA, ties.method = "average")/(length(x)+1)
q_emp <- x
qq_fitted <- do.call(paste0('q',distribution), c(list(p = u_emp), fit))
CM <- CDFt::CramerVonMisesTwoSamples(q_emp, qq_fitted)
KS <- CDFt::KolmogorovSmirnov(q_emp, qq_fitted)
MLE = -sum(log(do.call(paste0('d',distribution),c(list(x = x), fit))))
plotpos<-lmomco::pp(x=x,a=0,sort=FALSE)
theorquantiles = -do.call(paste0('q',distribution), c(list(p = plotpos), fit))
theorquantilessort<-sort(theorquantiles,decreasing=TRUE)[1:10]
samplesort<-sort(x,decreasing=TRUE)[1:10]
MSEquant<-sum((theorquantiles-x)^2)/length(x)
DiffOfMax<-((max(theorquantiles)-max(x))/max(x))*100
MeanDiffOf10Max<-sum(abs(theorquantilessort-samplesort))/10
# AIC = 2*length(fit)-2*sum(log(do.call(paste0('d',distribution),c(list(x = x), fit))))
# BIC = length(fit)*log(length(x))-2*sum(do.call(paste0('d',distribution),c(list(x = x), fit)))
GoF <- list(MLE=MLE, CM = CM, KS = KS,
MSEquant=MSEquant,DiffOfMax=DiffOfMax,MeanDiffOf10Max=MeanDiffOf10Max)
return(GoF)
}
GoF <- GOF_tests(x = x, fit = fit, distribution = 'expweibull')
distribution = 'expweibull'
u_emp <- rank(x, na.last = NA, ties.method = "average")/(length(x)+1)
View(x)
length(x)
rank(x, na.last = NA, ties.method = "average")
u_emp <- rank(coredata(x), na.last = NA, ties.method = "average")/(length(x)+1)
q_emp <- x
qq_fitted <- do.call(paste0('q',distribution), c(list(p = u_emp), fit))
CM <- CDFt::CramerVonMisesTwoSamples(q_emp, qq_fitted)
KS <- CDFt::KolmogorovSmirnov(q_emp, qq_fitted)
MLE = -sum(log(do.call(paste0('d',distribution),c(list(x = x), fit))))
CM <- CDFt::CramerVonMisesTwoSamples(q_emp, qq_fitted)
View(q_emp)
q_emp <- coredata(x)
qq_fitted <- do.call(paste0('q',distribution), c(list(p = u_emp), fit))
CM <- CDFt::CramerVonMisesTwoSamples(q_emp, qq_fitted)
KS <- CDFt::KolmogorovSmirnov(q_emp, qq_fitted)
MLE = -sum(log(do.call(paste0('d',distribution),c(list(x = x), fit))))
plotpos<-lmomco::pp(x=x,a=0,sort=FALSE)
theorquantiles = -do.call(paste0('q',distribution), c(list(p = plotpos), fit))
theorquantilessort<-sort(theorquantiles,decreasing=TRUE)[1:10]
samplesort<-sort(x,decreasing=TRUE)[1:10]
MSEquant<-sum((theorquantiles-x)^2)/length(x)
DiffOfMax<-((max(theorquantiles)-max(x))/max(x))*100
MeanDiffOf10Max<-sum(abs(theorquantilessort-samplesort))/10
GoF <- list(MLE=MLE, CM = CM, KS = KS,
MSEquant=MSEquant,DiffOfMax=DiffOfMax,MeanDiffOf10Max=MeanDiffOf10Max)
remove.packages("anyFit")
devtools::document()
devtools::document()
devtools::install()
library(anyFit)
file_path <- system.file("extdata", "KNMI_Daily.csv", package = "anyFit")
time_zone <- "UTC"
data <- delim2xts(file_path = file_path,
time_zone = "UTC", delim = " ", strict_step = TRUE)
params <- fitlm_expweibull(data[,4], ignore_zeros = TRUE)
params$Param
params$GoF
fit_check <- fit_diagnostics(data[,4], dist = 'expweibull',
params = params$Param, ignore_zeros = TRUE)
fit_check$Diagnostic_Plots
candidates <- list('exp','expweibull', 'gamma3')
fits <- fitlm_multi(data['2010',4],candidates = candidates, ignore_zeros = TRUE)
fits$diagnostics
ts_lmoms <- lmom_stats(data, ignore_zeros = TRUE)
lcheck <- LRatio_check(ts_lmoms)
lcheck$multi_plots
candidates <- list('exp','weibull', 'gamma3')
monthly_fits <- fitlm_monthly(smonthly_ts,candidates = candidates, ignore_zeros = TRUE)
agg_ts <- aggregate_xts(ts = data[,4], periods = c("months","quarters","years"), FUN = 'sum')
smonthly_ts <- agg_ts$list_months$aggregated
agg_ts$Combined_Plot
monthly_fits <- fitlm_monthly(smonthly_ts,candidates = candidates, ignore_zeros = TRUE)
monthly_fits$monthly_QQplot
